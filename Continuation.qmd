# Setting up Locally

Within the InstrumentQC data, there is a data folder with individual archive folders for each instrument. Modify the names accordingly for your own setting. Within the archived folder, delete the existing files that contain our institutions data.

Next, you will need to modify the existing Rscript to match the following names, and to point at the Cytekbio Setup folder containing the DailyQC files and to the folder containing the bead .fcs files used as part of the MFI monitoring. Make sure these are correct.

Now, on the upper right hand side, hit the Source option. This should trigger the processing of the entire R script needed to process the past data. If it fails, you will need to troubleshoot whether the file.path your provided is the correct one (most likely error) or an R package dependency is missing (in which case it would need to be installed).

Once complete, you should see the processed data is now present within the Archive folder.

Open up the equivalent .qmd file for your given instrument. This file is what will build the dashboard for the equivalent instrument page on the website. Make sure to similarly modify the file.paths at the top of the file so they match your Archive folder for that project. Once done, hit render button and wait, troubleshooting as needed. Both R script and .qmd will be specific and search for the data within those folders, so we anticipate less issues.

Once done, either a browser window will open showing the data for the instrument, or you will need to go to InstrumentQC, docs folder and open the index.html file to see a local rendered version of the file. Once you are here, congratulations, the basic install for your instrument has been carried out successfully. Repeat for the other instruments for the time being.

# Automating Transfer

Now that the initial set up of InstrumentQC data folder with archive data, and the R script QMD file paths are sorted, its time to figure out how to produce new data. One way of doing this would be to do so manually. We provide examples of a staff.qmd file where once you set up the filepath to the Rscript, you only need to hit the Run Current Code chunk to automatically process any new data.

An alternative is to go for an automated approach. This relies on the Windows Task Scheduler, that sets when updates are run. Our institution the QC is generally done on our instruments by 10:30 AM, so we set the task scheduler to go for that time. Likewise, if manually been done before this point, it produces a flag profile that skips processing the data again. This flag file gets eliminated later in the day, and an update is pulled in at 6 AM to reduce processing time during peak hours.

Regardless of approach, ultimately you end up with new processed data. These changes are tracked by Git as part of version control. These in turn can be pushed to GitHub which provides the processed data to where the main computer or github action needed to render the dashboard can have access to it. We will also when setting up taskscheduler set them to two minutes apart to avoid having issues with the pull push versions when transferring.

# Building the Dashboard

Now that we have the individual instruments setup and transferring the data to GitHub, let's talk dashboard website structure. The plots we can see locally in the .qmd file get rolled out as their own interactive webpage. If your instrument has additional parameters, by delving into the code you can modify what gets included or excluded. It helps to have someone with R experience to help with this customization if you are unfamiliar. R is your playground, you can customize what gets included in a Quarto document for practically anytime if you invest the time.

The combination of each instruments .qmd file forms the websites main pages. The additional pages in our example are index.qmd that forms the home page, which also has the R code needed to access all the data across instruments archive data to provide the summary visual and the 6 month history. Make sure the file paths are updated here accordingly or it will fail out.

Additional .qmd files for help and data are present rendering mostly independently of each other. All the above individual pages are cobbled together into the overall website by means of the \_yaml file.

To begin, you can start locally by navigating to terminal, and quarto render the project folder. This will generate the local version. You can then git commit all the generated html files and push to GitHub.

Next, navigate to GitHub, navigate to the repositories settings and set the page to be visualized from the main branch and the docs folder. Wait three minutes, and then navigate to the username.github.io/InstrumentQC style url to visualize your dashboard. Repeat edits to the code and pushes until you have it customized to how you want the visual apperance.

# Github Actions

Rendering locally takes computer time. Additionally, it means each instrument needs to bring in edited versions of the website locally every morning with their initial pull. Alternatively, we can set up a github-pages branch where the rendered website remains on the web and not on the local computer, and customize a Github Actions at the repository level that will spin up a Cloud instance to generate the website. This is free for public github repositories up to certain allowances that our website doesn't approach with a once daily frequency. The flip-side is it's more complicated technical and can take longer due to needing to install R and the R packages needed to run everything on the cloud instance each time. For those with R experience or who laugh in face of danger, read on.
